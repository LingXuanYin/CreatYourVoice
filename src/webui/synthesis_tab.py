"""è¯­éŸ³åˆæˆç•Œé¢

é‡æ–°è®¾è®¡çš„ç®€åŒ–ç‰ˆæœ¬ï¼š
- å››ç§æƒ…æ„Ÿæ§åˆ¶æ¨¡å¼ï¼šæ™®é€šã€æè¿°ã€å‚è€ƒã€å‘é‡
- å•æ å¸ƒå±€ï¼Œå“åº”å¼è®¾è®¡
- ç®€åŒ–çš„å‚æ•°é…ç½®
- å®æ—¶çŠ¶æ€åé¦ˆ
"""

import gradio as gr
from typing import Dict, List, Tuple, Optional, Any
import logging

from ..core.voice_manager import VoiceManager
from ..integrations.index_tts import IndexTTSIntegration

logger = logging.getLogger(__name__)


class SynthesisTab:
    """è¯­éŸ³åˆæˆTab

    ç®€åŒ–è®¾è®¡åŸåˆ™ï¼š
    1. æ¸…æ™°çš„å·¥ä½œæµï¼šé€‰æ‹©éŸ³è‰² â†’ è¾“å…¥æ–‡æœ¬ â†’ æƒ…æ„Ÿæ§åˆ¶ â†’ ç”Ÿæˆ
    2. å››ç§æƒ…æ„Ÿæ¨¡å¼ï¼Œæ»¡è¶³ä¸åŒéœ€æ±‚
    3. å“åº”å¼å•æ å¸ƒå±€
    """

    def __init__(self, voice_manager: VoiceManager, index_tts_integration: IndexTTSIntegration):
        """åˆå§‹åŒ–åˆæˆTab"""
        self.voice_manager = voice_manager
        self.index_tts_integration = index_tts_integration

        # å½“å‰çŠ¶æ€
        self._current_voice_config: Optional[Any] = None
        self._synthesis_history: List[Dict[str, Any]] = []

    def create_interface(self):
        """åˆ›å»ºç•Œé¢"""
        gr.Markdown("""
        ## ğŸ¤ è¯­éŸ³åˆæˆ

        ä½¿ç”¨IndexTTSè¿›è¡Œæ–‡æœ¬è½¬è¯­éŸ³åˆæˆï¼Œæ”¯æŒå¤šç§æƒ…æ„Ÿæ§åˆ¶æ¨¡å¼ã€‚
        ğŸ’¡ **æ¶æ„è¯´æ˜**ï¼šIndexTTSæ˜¯çº¯æ–‡æœ¬è½¬è¯­éŸ³æ¨¡å‹ï¼Œæ— speakeræ¦‚å¿µï¼Œåªæœ‰æƒ…æ„Ÿæ§åˆ¶ã€‚
        """)

        # å•æ å“åº”å¼å¸ƒå±€
        with gr.Column():
            # æ­¥éª¤1ï¼šä¸Šä¼ å‚è€ƒéŸ³é¢‘
            with gr.Group():
                gr.Markdown("### æ­¥éª¤1ï¼šä¸Šä¼ è¯´è¯äººå‚è€ƒéŸ³é¢‘")
                gr.Markdown("ğŸ’¡ **IndexTTSæ¶æ„**ï¼šéœ€è¦ä¸Šä¼ å‚è€ƒéŸ³é¢‘æ¥å®šä¹‰è¯´è¯äººç‰¹å¾ï¼Œæ— éœ€é¢„å…ˆåˆ›å»ºéŸ³è‰²")

                speaker_audio = gr.Audio(
                    label="è¯´è¯äººå‚è€ƒéŸ³é¢‘",
                    type="filepath"
                )
                gr.Markdown("ğŸ’¡ ä¸Šä¼ åŒ…å«ç›®æ ‡è¯´è¯äººå£°éŸ³ç‰¹å¾çš„éŸ³é¢‘æ–‡ä»¶")

                speaker_audio_info = gr.Textbox(
                    label="éŸ³é¢‘ä¿¡æ¯",
                    value="è¯·ä¸Šä¼ å‚è€ƒéŸ³é¢‘",
                    interactive=False,
                    lines=2
                )

            # æ­¥éª¤2ï¼šè¾“å…¥æ–‡æœ¬
            with gr.Group():
                gr.Markdown("### æ­¥éª¤2ï¼šè¾“å…¥åˆæˆæ–‡æœ¬")

                text_input = gr.Textbox(
                    label="åˆæˆæ–‡æœ¬",
                    placeholder="è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬å†…å®¹...",
                    lines=4,
                    max_lines=10,
                    info="æ”¯æŒä¸­æ–‡ã€è‹±æ–‡ç­‰å¤šç§è¯­è¨€"
                )

                with gr.Row():
                    text_length_display = gr.Textbox(
                        label="æ–‡æœ¬é•¿åº¦",
                        value="0 å­—ç¬¦",
                        interactive=False,
                        scale=1
                    )
                    estimated_time_display = gr.Textbox(
                        label="é¢„ä¼°æ—¶é—´",
                        value="0 ç§’",
                        interactive=False,
                        scale=1
                    )

            # æ­¥éª¤3ï¼šæƒ…æ„Ÿæ§åˆ¶
            with gr.Group():
                gr.Markdown("### æ­¥éª¤3ï¼šæƒ…æ„Ÿæ§åˆ¶")

                emotion_mode = gr.Radio(
                    label="æƒ…æ„Ÿæ§åˆ¶æ¨¡å¼",
                    choices=[
                        ("æ™®é€šæ¨¡å¼ - ä½¿ç”¨éŸ³è‰²é»˜è®¤æƒ…æ„Ÿ", "normal"),
                        ("æƒ…æ„Ÿæè¿° - æ–‡æœ¬æè¿°æƒ…æ„Ÿ", "description"),
                        ("æƒ…æ„Ÿå‚è€ƒ - ä¸Šä¼ å‚è€ƒéŸ³é¢‘", "reference"),
                        ("é«˜çº§æ¨¡å¼ - 8ç»´æƒ…æ„Ÿå‘é‡", "vector")
                    ],
                    value="normal",
                    info="é€‰æ‹©é€‚åˆçš„æƒ…æ„Ÿæ§åˆ¶æ–¹å¼"
                )

                # æƒ…æ„Ÿæè¿°æ¨¡å¼
                with gr.Group(visible=False) as description_group:
                    emotion_description = gr.Textbox(
                        label="æƒ…æ„Ÿæè¿°",
                        placeholder="ä¾‹å¦‚ï¼šå¼€å¿ƒã€æ¿€åŠ¨ã€å……æ»¡æ´»åŠ›ã€æ¸©æŸ”ã€æ‚²ä¼¤...",
                        lines=2,
                        info="ç”¨æ–‡å­—æè¿°æƒ³è¦çš„æƒ…æ„Ÿè¡¨è¾¾"
                    )

                # æƒ…æ„Ÿå‚è€ƒæ¨¡å¼
                with gr.Group(visible=False) as reference_group:
                    emotion_reference = gr.Audio(
                        label="æƒ…æ„Ÿå‚è€ƒéŸ³é¢‘",
                        type="filepath"
                    )
                    gr.Markdown("ğŸ’¡ ä¸Šä¼ åŒ…å«ç›®æ ‡æƒ…æ„Ÿçš„éŸ³é¢‘æ–‡ä»¶")

                    emotion_weight = gr.Slider(
                        label="æƒ…æ„Ÿæƒé‡",
                        minimum=0.0,
                        maximum=1.0,
                        value=0.65,
                        step=0.05,
                        info="å‚è€ƒéŸ³é¢‘æƒ…æ„Ÿçš„å½±å“ç¨‹åº¦"
                    )

                # é«˜çº§å‘é‡æ¨¡å¼
                with gr.Group(visible=False) as vector_group:
                    gr.Markdown("#### 8ç»´æƒ…æ„Ÿå‘é‡æ§åˆ¶ (0.0-1.0)")

                    with gr.Row():
                        emotion_happy = gr.Slider(
                            label="é«˜å…´", minimum=0.0, maximum=1.0, value=0.0, step=0.1
                        )
                        emotion_angry = gr.Slider(
                            label="æ„¤æ€’", minimum=0.0, maximum=1.0, value=0.0, step=0.1
                        )
                        emotion_sad = gr.Slider(
                            label="æ‚²ä¼¤", minimum=0.0, maximum=1.0, value=0.0, step=0.1
                        )
                        emotion_afraid = gr.Slider(
                            label="ææƒ§", minimum=0.0, maximum=1.0, value=0.0, step=0.1
                        )

                    with gr.Row():
                        emotion_disgusted = gr.Slider(
                            label="åŒæ¶", minimum=0.0, maximum=1.0, value=0.0, step=0.1
                        )
                        emotion_surprised = gr.Slider(
                            label="æƒŠè®¶", minimum=0.0, maximum=1.0, value=0.0, step=0.1
                        )
                        emotion_calm = gr.Slider(
                            label="å¹³é™", minimum=0.0, maximum=1.0, value=1.0, step=0.1
                        )
                        emotion_neutral = gr.Slider(
                            label="ä¸­æ€§", minimum=0.0, maximum=1.0, value=0.0, step=0.1
                        )

                    with gr.Row():
                        normalize_vector_btn = gr.Button("å½’ä¸€åŒ–å‘é‡", size="sm")
                        reset_vector_btn = gr.Button("é‡ç½®å‘é‡", size="sm")
                        preset_happy_btn = gr.Button("é¢„è®¾ï¼šå¼€å¿ƒ", size="sm")
                        preset_sad_btn = gr.Button("é¢„è®¾ï¼šæ‚²ä¼¤", size="sm")

            # æ­¥éª¤4ï¼šç”Ÿæˆå‚æ•°
            with gr.Group():
                gr.Markdown("### æ­¥éª¤4ï¼šç”Ÿæˆå‚æ•°")

                with gr.Accordion("é«˜çº§å‚æ•°", open=False):
                    with gr.Row():
                        speed = gr.Slider(
                            label="è¯­é€Ÿ",
                            minimum=0.1,
                            maximum=3.0,
                            value=1.0,
                            step=0.1,
                            info="è¯­éŸ³æ’­æ”¾é€Ÿåº¦"
                        )
                        temperature = gr.Slider(
                            label="æ¸©åº¦",
                            minimum=0.1,
                            maximum=2.0,
                            value=0.8,
                            step=0.1,
                            info="ç”Ÿæˆéšæœºæ€§"
                        )

                    with gr.Row():
                        top_p = gr.Slider(
                            label="Top-p",
                            minimum=0.1,
                            maximum=1.0,
                            value=0.8,
                            step=0.05,
                            info="æ ¸é‡‡æ ·å‚æ•°"
                        )
                        top_k = gr.Slider(
                            label="Top-k",
                            minimum=1,
                            maximum=100,
                            value=30,
                            step=1,
                            info="å€™é€‰è¯æ•°é‡"
                        )

            # æ­¥éª¤5ï¼šå¼€å§‹åˆæˆ
            with gr.Group():
                gr.Markdown("### æ­¥éª¤5ï¼šå¼€å§‹åˆæˆ")

                with gr.Row():
                    synthesize_btn = gr.Button(
                        "ğŸ¤ å¼€å§‹åˆæˆ",
                        variant="primary",
                        scale=2,
                        elem_classes=["synthesis-btn"]
                    )
                    validate_btn = gr.Button(
                        "âœ… éªŒè¯å‚æ•°",
                        scale=1
                    )

                # è¿›åº¦å’ŒçŠ¶æ€æ˜¾ç¤º
                progress_display = gr.Textbox(
                    label="åˆæˆè¿›åº¦",
                    value="ç­‰å¾…å¼€å§‹...",
                    interactive=False,
                    lines=2
                )

            # ç»“æœæ˜¾ç¤º
            with gr.Group():
                gr.Markdown("### ğŸµ åˆæˆç»“æœ")

                with gr.Row():
                    with gr.Column(scale=2):
                        result_audio = gr.Audio(
                            label="åˆæˆéŸ³é¢‘",
                            interactive=False
                        )

                    with gr.Column(scale=1):
                        result_info = gr.JSON(
                            label="åˆæˆä¿¡æ¯",
                            value={}
                        )

                with gr.Row():
                    save_result_btn = gr.Button("ğŸ’¾ ä¿å­˜ç»“æœ")
                    download_result_btn = gr.Button("ğŸ“¥ ä¸‹è½½éŸ³é¢‘")

        # å­˜å‚¨ç»„ä»¶å¼•ç”¨
        self.components = {
            'speaker_audio': speaker_audio,
            'speaker_audio_info': speaker_audio_info,
            'text_input': text_input,
            'text_length_display': text_length_display,
            'estimated_time_display': estimated_time_display,
            'emotion_mode': emotion_mode,
            'description_group': description_group,
            'reference_group': reference_group,
            'vector_group': vector_group,
            'emotion_description': emotion_description,
            'emotion_reference': emotion_reference,
            'emotion_weight': emotion_weight,
            'emotion_happy': emotion_happy,
            'emotion_angry': emotion_angry,
            'emotion_sad': emotion_sad,
            'emotion_afraid': emotion_afraid,
            'emotion_disgusted': emotion_disgusted,
            'emotion_surprised': emotion_surprised,
            'emotion_calm': emotion_calm,
            'emotion_neutral': emotion_neutral,
            'normalize_vector_btn': normalize_vector_btn,
            'reset_vector_btn': reset_vector_btn,
            'preset_happy_btn': preset_happy_btn,
            'preset_sad_btn': preset_sad_btn,
            'speed': speed,
            'temperature': temperature,
            'top_p': top_p,
            'top_k': top_k,
            'synthesize_btn': synthesize_btn,
            'validate_btn': validate_btn,
            'progress_display': progress_display,
            'result_audio': result_audio,
            'result_info': result_info,
            'save_result_btn': save_result_btn,
            'download_result_btn': download_result_btn
        }

        # ç»‘å®šäº‹ä»¶
        self._bind_events()

        # åˆå§‹åŒ–æ•°æ®
        self._initialize_data()

    def _bind_events(self):
        """ç»‘å®šç•Œé¢äº‹ä»¶"""
        # å‚è€ƒéŸ³é¢‘ä¸Šä¼ 
        self.components['speaker_audio'].change(
            fn=self._on_speaker_audio_change,
            inputs=[self.components['speaker_audio']],
            outputs=[self.components['speaker_audio_info']]
        )

        # æ–‡æœ¬è¾“å…¥å˜åŒ–
        self.components['text_input'].change(
            fn=self._on_text_change,
            inputs=[self.components['text_input']],
            outputs=[
                self.components['text_length_display'],
                self.components['estimated_time_display']
            ]
        )

        # æƒ…æ„Ÿæ¨¡å¼åˆ‡æ¢
        self.components['emotion_mode'].change(
            fn=self._on_emotion_mode_change,
            inputs=[self.components['emotion_mode']],
            outputs=[
                self.components['description_group'],
                self.components['reference_group'],
                self.components['vector_group']
            ]
        )

        # å‘é‡æ§åˆ¶æŒ‰é’®
        self.components['normalize_vector_btn'].click(
            fn=self._normalize_emotion_vector,
            inputs=[
                self.components['emotion_happy'],
                self.components['emotion_angry'],
                self.components['emotion_sad'],
                self.components['emotion_afraid'],
                self.components['emotion_disgusted'],
                self.components['emotion_surprised'],
                self.components['emotion_calm'],
                self.components['emotion_neutral']
            ],
            outputs=[
                self.components['emotion_happy'],
                self.components['emotion_angry'],
                self.components['emotion_sad'],
                self.components['emotion_afraid'],
                self.components['emotion_disgusted'],
                self.components['emotion_surprised'],
                self.components['emotion_calm'],
                self.components['emotion_neutral']
            ]
        )

        self.components['reset_vector_btn'].click(
            fn=lambda: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],
            outputs=[
                self.components['emotion_happy'],
                self.components['emotion_angry'],
                self.components['emotion_sad'],
                self.components['emotion_afraid'],
                self.components['emotion_disgusted'],
                self.components['emotion_surprised'],
                self.components['emotion_calm'],
                self.components['emotion_neutral']
            ]
        )

        self.components['preset_happy_btn'].click(
            fn=lambda: [0.8, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0],
            outputs=[
                self.components['emotion_happy'],
                self.components['emotion_angry'],
                self.components['emotion_sad'],
                self.components['emotion_afraid'],
                self.components['emotion_disgusted'],
                self.components['emotion_surprised'],
                self.components['emotion_calm'],
                self.components['emotion_neutral']
            ]
        )

        self.components['preset_sad_btn'].click(
            fn=lambda: [0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.2, 0.0],
            outputs=[
                self.components['emotion_happy'],
                self.components['emotion_angry'],
                self.components['emotion_sad'],
                self.components['emotion_afraid'],
                self.components['emotion_disgusted'],
                self.components['emotion_surprised'],
                self.components['emotion_calm'],
                self.components['emotion_neutral']
            ]
        )

        # éªŒè¯å‚æ•°
        self.components['validate_btn'].click(
            fn=self._validate_parameters,
            inputs=self._get_all_inputs(),
            outputs=[self.components['progress_display']]
        )

        # å¼€å§‹åˆæˆ
        self.components['synthesize_btn'].click(
            fn=self._synthesize_speech,
            inputs=self._get_all_inputs(),
            outputs=[
                self.components['result_audio'],
                self.components['result_info'],
                self.components['progress_display']
            ]
        )

    def _get_all_inputs(self) -> List[gr.Component]:
        """è·å–æ‰€æœ‰è¾“å…¥ç»„ä»¶"""
        return [
            self.components['speaker_audio'],
            self.components['text_input'],
            self.components['emotion_mode'],
            self.components['emotion_description'],
            self.components['emotion_reference'],
            self.components['emotion_weight'],
            self.components['emotion_happy'],
            self.components['emotion_angry'],
            self.components['emotion_sad'],
            self.components['emotion_afraid'],
            self.components['emotion_disgusted'],
            self.components['emotion_surprised'],
            self.components['emotion_calm'],
            self.components['emotion_neutral'],
            self.components['speed'],
            self.components['temperature'],
            self.components['top_p'],
            self.components['top_k']
        ]

    def _initialize_data(self):
        """åˆå§‹åŒ–æ•°æ®"""
        logger.info("è¯­éŸ³åˆæˆTabåˆå§‹åŒ–å®Œæˆ")

    def _on_speaker_audio_change(self, audio_path: str) -> str:
        """å‚è€ƒéŸ³é¢‘ä¸Šä¼ æ—¶çš„å¤„ç†"""
        if not audio_path:
            return "è¯·ä¸Šä¼ å‚è€ƒéŸ³é¢‘"

        try:
            import librosa
            from pathlib import Path

            # è·å–éŸ³é¢‘ä¿¡æ¯
            audio_file = Path(audio_path)
            if not audio_file.exists():
                return "éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨"

            # åŠ è½½éŸ³é¢‘è·å–åŸºæœ¬ä¿¡æ¯
            y, sr = librosa.load(audio_path, sr=None)
            duration = len(y) / sr

            info = f"âœ… éŸ³é¢‘ä¸Šä¼ æˆåŠŸ\n"
            info += f"æ–‡ä»¶å: {audio_file.name}\n"
            info += f"æ—¶é•¿: {duration:.2f}ç§’\n"
            info += f"é‡‡æ ·ç‡: {sr}Hz"

            return info

        except Exception as e:
            logger.error(f"å¤„ç†å‚è€ƒéŸ³é¢‘å¤±è´¥: {e}")
            return f"âŒ éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}"

    def _on_text_change(self, text: str) -> Tuple[str, str]:
        """æ–‡æœ¬å˜åŒ–æ—¶çš„å¤„ç†"""
        length = len(text) if text else 0
        # ç®€å•çš„æ—¶é—´ä¼°ç®—ï¼šæ¯100å­—ç¬¦çº¦éœ€è¦10ç§’
        estimated_seconds = max(5, length // 10)

        return f"{length} å­—ç¬¦", f"çº¦ {estimated_seconds} ç§’"

    def _on_emotion_mode_change(self, mode: str) -> Tuple[bool, bool, bool]:
        """æƒ…æ„Ÿæ¨¡å¼åˆ‡æ¢"""
        return (
            mode == "description",  # description_group
            mode == "reference",    # reference_group
            mode == "vector"        # vector_group
        )

    def _normalize_emotion_vector(self, *values) -> Tuple[float, ...]:
        """å½’ä¸€åŒ–æƒ…æ„Ÿå‘é‡"""
        try:
            total = sum(values)
            if total > 0:
                normalized = [v / total for v in values]
                return tuple(normalized)
            else:
                # å¦‚æœå…¨ä¸º0ï¼Œè®¾ç½®ä¸ºå¹³é™
                return (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0)
        except Exception:
            return values

    def _validate_parameters(self, *args) -> str:
        """éªŒè¯åˆæˆå‚æ•°"""
        try:
            speaker_audio, text, emotion_mode = args[0], args[1], args[2]

            errors = []

            if not speaker_audio:
                errors.append("è¯·ä¸Šä¼ è¯´è¯äººå‚è€ƒéŸ³é¢‘")

            if not text.strip():
                errors.append("è¯·è¾“å…¥åˆæˆæ–‡æœ¬")

            if emotion_mode == "description" and not args[3].strip():
                errors.append("è¯·è¾“å…¥æƒ…æ„Ÿæè¿°")

            if emotion_mode == "reference" and not args[4]:
                errors.append("è¯·ä¸Šä¼ æƒ…æ„Ÿå‚è€ƒéŸ³é¢‘")

            if errors:
                return f"âŒ å‚æ•°éªŒè¯å¤±è´¥:\n" + "\n".join(f"â€¢ {error}" for error in errors)
            else:
                return "âœ… å‚æ•°éªŒè¯é€šè¿‡ï¼Œå¯ä»¥å¼€å§‹åˆæˆ"

        except Exception as e:
            return f"âŒ å‚æ•°éªŒè¯å¤±è´¥: {e}"

    def _synthesize_speech(self, *args) -> Tuple[Optional[str], Dict[str, Any], str]:
        """æ‰§è¡Œè¯­éŸ³åˆæˆ"""
        try:
            # è§£æå‚æ•°
            speaker_audio = args[0]
            text = args[1]
            emotion_mode = args[2]

            # éªŒè¯å‚æ•°
            if not speaker_audio:
                return None, {"é”™è¯¯": "è¯·ä¸Šä¼ è¯´è¯äººå‚è€ƒéŸ³é¢‘"}, "âŒ åˆæˆå¤±è´¥"

            if not text.strip():
                return None, {"é”™è¯¯": "è¯·è¾“å…¥åˆæˆæ–‡æœ¬"}, "âŒ åˆæˆå¤±è´¥"

            # æ„å»ºIndexTTSåˆæˆå‚æ•°
            synthesis_kwargs = {
                "text": text.strip(),
                "speaker_audio": speaker_audio,
                "emotion_control_method": emotion_mode,
                "do_sample": True,
                "top_p": args[16],
                "top_k": args[17],
                "temperature": args[15],
                "length_penalty": 0.0,
                "num_beams": 3,
                "repetition_penalty": 10.0,
                "max_mel_tokens": 1500,
            }

            # æ ¹æ®æƒ…æ„Ÿæ¨¡å¼æ·»åŠ å‚æ•°
            if emotion_mode == "description":
                synthesis_kwargs["emotion_text"] = args[3]
            elif emotion_mode == "reference":
                synthesis_kwargs["emotion_audio"] = args[4]
                synthesis_kwargs["emotion_weight"] = args[5]
            elif emotion_mode == "vector":
                synthesis_kwargs["emotion_vector"] = list(args[6:14])

            # æ‰§è¡ŒIndexTTSåˆæˆ
            result = self.index_tts_integration.infer(**synthesis_kwargs)

            # æ„å»ºç»“æœä¿¡æ¯
            result_info = {
                "çŠ¶æ€": "åˆæˆæˆåŠŸ",
                "æ–‡æœ¬é•¿åº¦": len(text),
                "æƒ…æ„Ÿæ¨¡å¼": emotion_mode,
                "å¤„ç†æ—¶é—´": f"{result.processing_time:.2f}ç§’",
                "åˆ†æ®µæ•°": result.segments_count,
                "æƒ…æ„Ÿä¿¡æ¯": result.emotion_info
            }

            # ä¿å­˜åˆ°å†å²
            self._synthesis_history.append({
                "timestamp": "2024-01-01 12:00:00",
                "text": text[:50] + "..." if len(text) > 50 else text,
                "emotion_mode": emotion_mode,
                "success": True
            })

            # è¿”å›éŸ³é¢‘è·¯å¾„æˆ–æ•°æ®
            if result.audio_path:
                return result.audio_path, result_info, "âœ… åˆæˆå®Œæˆ"
            elif result.audio_data:
                # å¦‚æœè¿”å›çš„æ˜¯éŸ³é¢‘æ•°æ®ï¼Œéœ€è¦ä¿å­˜ä¸ºæ–‡ä»¶
                import tempfile
                import soundfile as sf

                with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
                    sf.write(tmp_file.name, result.audio_data[1], result.audio_data[0])
                    return tmp_file.name, result_info, "âœ… åˆæˆå®Œæˆ"
            else:
                return None, result_info, "âœ… åˆæˆå®Œæˆï¼ˆæ— éŸ³é¢‘è¾“å‡ºï¼‰"

        except Exception as e:
            logger.error(f"è¯­éŸ³åˆæˆå¤±è´¥: {e}")
            return None, {"é”™è¯¯": str(e)}, "âŒ åˆæˆå¤±è´¥"
